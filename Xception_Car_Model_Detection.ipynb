{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMqJcL/BnBARK/pbYaIW8+L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belanasaikiran/Team-6-Big-Data-Project/blob/main/Xception_Car_Model_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "G3GaYYwe32So",
        "outputId": "896aa665-7936-47ac-ad88-7017e3e47534"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'channels_last'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "import PIL\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import backend as K\n",
        "from keras import layers, models, optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import *\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "K.image_data_format()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "k_folds = 2\n",
        "TTA_STEPS = 5\n",
        "PATIENCE = 6\n",
        "SEED = 2019\n",
        "BASE_MODEL = Xception\n",
        "IMAGE_SIZE = 299"
      ],
      "metadata": {
        "id": "avGhqJvY39I0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ne-_s_eAZHr",
        "outputId": "5c202474-0eab-4f9e-dbad-4f09856a9724"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/MyDrive/2019-3rd-ml-month-with-kakr.zip > /dev/null # output to null"
      ],
      "metadata": {
        "id": "DYgdaf-mAOLP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/'\n",
        "\n",
        "TRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\n",
        "TEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n",
        "\n",
        "df_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
        "df_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
        "df_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))\n",
        "\n",
        "model_path = '/content/'\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)"
      ],
      "metadata": {
        "id": "xpKdXrd-4FPE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_path = '/contnet/'\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "def crop_boxing_img(img_name, margin=0, size=(IMAGE_SIZE,IMAGE_SIZE)):\n",
        "    if img_name.split('_')[0] == 'train':\n",
        "        PATH = TRAIN_IMG_PATH\n",
        "        data = df_train\n",
        "    else:\n",
        "        PATH = TEST_IMG_PATH\n",
        "        data = df_test\n",
        "\n",
        "    img = PIL.Image.open(os.path.join(PATH, img_name))\n",
        "    pos = data.loc[data[\"img_file\"] == img_name, ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n",
        "\n",
        "    width, height = img.size\n",
        "    x1 = max(0, pos[0] - margin)\n",
        "    y1 = max(0, pos[1] - margin)\n",
        "    x2 = min(pos[2] + margin, width)\n",
        "    y2 = min(pos[3] + margin, height)\n",
        "\n",
        "    return img.crop((x1, y1, x2, y2)).resize(size)"
      ],
      "metadata": {
        "id": "ObE7V1Eg4HgI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "TRAIN_CROPPED_PATH = '/content/cropped_train'\n",
        "TEST_CROPPED_PATH = '/content/cropped_test'\n",
        "\n",
        "if (os.path.isdir(TRAIN_CROPPED_PATH) == False):\n",
        "    os.mkdir(TRAIN_CROPPED_PATH)\n",
        "\n",
        "if (os.path.isdir(TEST_CROPPED_PATH) == False):\n",
        "    os.mkdir(TEST_CROPPED_PATH)\n",
        "\n",
        "for i, row in df_train.iterrows():\n",
        "    cropped = crop_boxing_img(row['img_file'])\n",
        "    cropped.save(os.path.join(TRAIN_CROPPED_PATH, row['img_file']))\n",
        "\n",
        "for i, row in df_test.iterrows():\n",
        "    cropped = crop_boxing_img(row['img_file'])\n",
        "    cropped.save(os.path.join(TEST_CROPPED_PATH, row['img_file']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95eiSkg7A_0k",
        "outputId": "a8840677-1d86-4f88-ae2b-81e9f492be10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 52s, sys: 6.83 s, total: 2min 59s\n",
            "Wall time: 3min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['class'] = df_train['class'].astype('str')\n",
        "df_train = df_train[['img_file', 'class']]\n",
        "df_test = df_test[['img_file']]"
      ],
      "metadata": {
        "id": "BeOMUbkyBBOd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "WAFrpmLlBD8E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_callback(model_name, patient):\n",
        "    ES = EarlyStopping(\n",
        "        monitor='val_f1_m',\n",
        "        patience=patient,\n",
        "        mode='max',\n",
        "        verbose=1)\n",
        "    RR = ReduceLROnPlateau(\n",
        "        monitor = 'val_f1_m',\n",
        "        factor = 0.5,\n",
        "        patience = patient / 2,\n",
        "        min_lr=0.000001,\n",
        "        verbose=1,\n",
        "        mode='max')\n",
        "    MC = ModelCheckpoint(\n",
        "        filepath=model_name,\n",
        "        monitor='val_f1_m',\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode='max')\n",
        "\n",
        "    return [ES, RR, MC]"
      ],
      "metadata": {
        "id": "72yIogeiBFdR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model_name, iamge_size):\n",
        "    base_model = model_name(weights='imagenet', input_shape=(iamge_size,iamge_size,3), include_top=False)\n",
        "    #base_model.trainable = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    model.add(layers.Dense(2048, activation='relu', kernel_initializer='he_normal'))\n",
        "    model.add(layers.Dropout(0.15))\n",
        "\n",
        "    model.add(layers.Dense(196, activation='softmax', kernel_initializer='lecun_normal'))\n",
        "    #model.summary()\n",
        "\n",
        "    optimizer = optimizers.Nadam(lr=0.0003)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc', f1_m, precision_m, recall_m])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "HwGYh4qREJ6n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser\n"
      ],
      "metadata": {
        "id": "x00X757QELhH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    #featurewise_center= True,  # set input mean to 0 over the dataset\n",
        "    #samplewise_center=True,  # set each sample mean to 0\n",
        "    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n",
        "    #samplewise_std_normalization=True,  # divide each input by its std\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    zoom_range=0.3,\n",
        "    shear_range=0.5,\n",
        "    brightness_range=[0.5, 1.5],\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function = get_random_eraser(v_l=0, v_h=255),\n",
        "    )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    #featurewise_center= True,  # set input mean to 0 over the dataset\n",
        "    #samplewise_center=True,  # set each sample mean to 0\n",
        "    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n",
        "    #samplewise_std_normalization=True  # divide each input by its std\n",
        "    )\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    #featurewise_center= True,  # set input mean to 0 over the dataset\n",
        "    #samplewise_center=True,  # set each sample mean to 0\n",
        "    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n",
        "    #samplewise_std_normalization=True,  # divide each input by its std\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    zoom_range=0.3,\n",
        "    shear_range=0.5,\n",
        "    brightness_range=[0.5, 1.5],\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function = get_random_eraser(v_l=0, v_h=255),\n",
        "    )"
      ],
      "metadata": {
        "id": "A1eJ40FEEQP9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=k_folds)\n",
        "#skf = KFold(n_splits=k_folds, random_state=SEED)"
      ],
      "metadata": {
        "id": "vO3Xn_UAEUdK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "j = 1\n",
        "model_names = []\n",
        "for (train_index, valid_index) in skf.split(\n",
        "    df_train['img_file'],\n",
        "    df_train['class']):\n",
        "\n",
        "\n",
        "    traindf = df_train\n",
        "    validdf = df_train.iloc[valid_index, :].reset_index()\n",
        "\n",
        "    print(\"=========================================\")\n",
        "    print(\"====== K Fold Validation step => %d/%d =======\" % (j,k_folds))\n",
        "    print(\"=========================================\")\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=traindf,\n",
        "        directory=TRAIN_CROPPED_PATH,\n",
        "        x_col='img_file',\n",
        "        y_col='class',\n",
        "        target_size= (IMAGE_SIZE, IMAGE_SIZE),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED,\n",
        "        shuffle=True\n",
        "        )\n",
        "\n",
        "    valid_generator = valid_datagen.flow_from_dataframe(\n",
        "        dataframe=validdf,\n",
        "        directory=TRAIN_CROPPED_PATH,\n",
        "        x_col='img_file',\n",
        "        y_col='class',\n",
        "        target_size= (IMAGE_SIZE, IMAGE_SIZE),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED,\n",
        "        shuffle=True\n",
        "        )\n",
        "\n",
        "    model_name = model_path + str(j) + '_' + 'Xception' + '.hdf5'\n",
        "    model_names.append(model_name)\n",
        "\n",
        "    model = get_model(BASE_MODEL, IMAGE_SIZE)\n",
        "\n",
        "    try:\n",
        "        model.load_weights(model_name)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(traindf.index) / BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=valid_generator,\n",
        "        validation_steps=len(validdf.index) / BATCH_SIZE,\n",
        "        verbose=1,\n",
        "        shuffle=False,\n",
        "        callbacks = get_callback(model_name, PATIENCE)\n",
        "        )\n",
        "\n",
        "    j+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-IqbcDAEcaB",
        "outputId": "4411ac19-c6a4-4a56-a976-34f5cf799f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================\n",
            "====== K Fold Validation step => 1/2 =======\n",
            "=========================================\n",
            "Found 9990 validated image filenames belonging to 196 classes.\n",
            "Found 4995 validated image filenames belonging to 196 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Nadam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())"
      ],
      "metadata": {
        "id": "GIJF_HRvEoUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7), dpi= 80, facecolor='w', edgecolor='k')\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aMbqfsWhFTIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7), dpi= 80, facecolor='w', edgecolor='k')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m7GrN782FTXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7), dpi= 80, facecolor='w', edgecolor='k')\n",
        "plt.plot(history.history['f1_m'])\n",
        "plt.plot(history.history['val_f1_m'])\n",
        "plt.title('model f1_score')\n",
        "plt.ylabel('f1_score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7WBAjv2tFjbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=df_test,\n",
        "    directory=TEST_CROPPED_PATH,\n",
        "    x_col='img_file',\n",
        "    y_col=None,\n",
        "    target_size= (IMAGE_SIZE, IMAGE_SIZE),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "waIxCEGKFlb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = []\n",
        "for i, name in enumerate(model_names):\n",
        "    model = get_model(BASE_MODEL, IMAGE_SIZE)\n",
        "    model.load_weights(name)\n",
        "\n",
        "    preds = []\n",
        "    for j in range(TTA_STEPS):\n",
        "        test_generator.reset()\n",
        "        pred = model.predict_generator(\n",
        "            generator=test_generator,\n",
        "            steps = len(df_test)/BATCH_SIZE,\n",
        "            verbose=1\n",
        "        )\n",
        "        preds.append(pred)\n",
        "    pred_tta = np.mean(preds, axis=0)\n",
        "    prediction.append(pred_tta)\n",
        "\n",
        "y_pred = np.mean(prediction, axis=0)"
      ],
      "metadata": {
        "id": "CYxZyOvzFoFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_class_indices=np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "id": "aGVdh2P-FpGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "final_pred = [labels[k] for k in preds_class_indices]"
      ],
      "metadata": {
        "id": "hOAoUNkqFsq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_result = pd.read_csv(os.path.join(DATA_PATH, 'final_result.csv'))\n",
        "final_result[\"class\"] = final_pred\n",
        "final_result.to_csv(\"final_result.csv\", index=False)\n",
        "final_result.head()"
      ],
      "metadata": {
        "id": "RXXO4DYlFt5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lpUtiKl_F1ou"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}